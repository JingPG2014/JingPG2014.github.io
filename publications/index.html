<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Peiguang Jing </title> <meta name="author" content="Peiguang Jing "> <meta name="description" content="publications by categories in reversed chronological order."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%96%A5%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/news/assets/css/main.css"> <link rel="canonical" href="https://peiguangjing.github.io/news/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/news/assets/js/theme.js"></script> <script src="/news/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/news/"><span class="font-weight-bold">Peiguang Jing </span></a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/news/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/news/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/news/cv/">CV</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/news/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/news/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">publications by categories in reversed chronological order.</p> </header> <article> <div class="publications"> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="10330746" class="col-sm-10"> <div class="title">Deep Multi-modal Hashing with Semantic Enhancement for Multi-label Micro-video Retrieval</div> <div class="author"> <em>Peiguang Jing</em>, Haoyi Sun, Liqiang Nie, Yun Li, and Yuting Su</div> <div class="periodical"> <em>IEEE Transactions on Knowledge and Data Engineering</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10330746" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/haoyi199815/DMHSE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>The pressing need for low storage and high efficiency has significantly propelled the advancement of deep hashing techniques in the realm of large-scale search and retrieval tasks. As one of the most prevailing forms of user-generated contents, micro-videos usually represent more complicated multi-modal behaviors that are further challenged in multi-label retrieval. Existing multi-modal hashing methods tend to prioritize the complementarity and consistency in multi-modal fusion, while neglecting the completeness problem. In this paper, we propose a deep multi-modal hashing with semantic enhancement (DMHSE) method that effectively integrates complete multi-modal representation learning with discriminative binary coding by means of collaboration between two distinct encoders, FoldCoder and HashCoder. FoldCoder translates latent multi-modal representation learning to a degradation process through mimicking data transmitting. Further, it incorporates a prompt learning paradigm to maximize the utilization of multi-label semantics for guiding representation learning. HashCoder combines pairwise and central constraints to ensure more discriminative hashing results. Pairwise constraint preserves the original local relevance structure, while central constraint tackles the problem of semantic ambiguity in multi-label data by leveraging the global label distribution. Experimental results demonstrate that DMHSE achieves superior performance in multi-label micro-video retrieval tasks.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="jing2023dual" class="col-sm-10"> <div class="title">Dual Preference Perception Network for Fashion Recommendation in the Social Internet of Things</div> <div class="author"> <em>Peiguang Jing</em>, Kai Zhang, Xianyi Liu, Yun Li, Yu Liu, and Yuting Su</div> <div class="periodical"> <em>IEEE Internet of Things Journal</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10286302" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/KaiZhang1228/DP2Net" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Nowadays, with the continuous development of information technology, the application scenarios of the Internet of Things (IoT) are progressively expanding to the social field, engendering widespread attention to the Social Internet of Things (SIoT). Personalized fashion recommendation that possesses the potential to establish social relationships between clothing and humans has substantially broadened the scope of the SIoT, particularly with the flourishing fashion industry and the ascent of smart home. Compared to conventional recommendations, fashion recommendation generally suggests a collection of items rather than individual pieces for users. Additionally, considering the public acceptance alongside the user-specific preference is reasonable for fashion recommendation, however, current methods often overlook the former. To comprehensively capture the public acceptance and the user-specific preference, we propose a dual preference perception network (DP2Net) for fashion recommendation. Firstly, a fashion corpus is constructed to facilitate the condensation of general taste, wherein adversarial learning and determinantal point process are leveraged to ensure representativeness and diversity of the corpus. Secondly, a user-general preference perception module is built based on a bottleneck transformer structure to generate aggregated representations for the corpus. Thirdly, a user-specific preference perception module is constructed to acquire collaborative representations of users and outfits by employing an attentive heterogeneous graph embedding. The final loss functions of two preference perception modules are constructed by combining the representations of users, outfits, and the corpus. Experiments on large-scale real-world datasets demonstrate the effectiveness of the proposed method.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="luvmenet" class="col-sm-10"> <div class="title">VMemNet: A Deep Collaborative Spatial-Temporal Network With Attention Representation for Video Memorability Prediction</div> <div class="author"> Wei Lu, Yujia Zhai, Jiaze Han, <em>Peiguang Jing</em>, Yu Liu, and Yuting Su</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10298788" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/accelerate20000/VMemNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Video memorability measures the degree to which a video is remembered by different viewers and has shown great potential in various contexts, including advertising, education, and health care. While extensive research has been conducted on image memorability, the study of video memorability is still in its early stages. Existing methods in this field primarily focus on coarse-grained spatial feature representation and decision fusion strategies, overlooking the crucial interactions between spatial and temporal domains. Therefore, we propose an end-to-end collaborative spatial-temporal network called VMemNet, which incorporates targeted attention mechanisms and intermediation fusion strategies. This enables VMemNet to capture the intricate relationships between spatial and temporal information and uncover more elements of memorability within video visual features. VMemNet integrates spatially and semantically guided attention modules into a dual-stream network architecture, allowing it to simultaneously capture static local cues and dynamic global cues in videos. Specifically, the spatial attention module is used to aggregate more memorable elements from spatial locations, and the semantically guided attention module is used to achieve semantic alignment and intermediate fusion of the local and global cues. In addition, two types of loss functions with complementary decision rules are associated with the corresponding attention modules to guide the training process of the proposed network. Experimental results obtained on a publicly available dataset verify that the proposed VMemNet approach outperforms all current single- and multi-modal methods in terms of video memorability prediction.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="jing2023duam" class="col-sm-10"> <div class="title">Dual Preference Perception Network for Fashion Recommendation in the Social Internet of Things</div> <div class="author"> <em>Peiguang Jing</em>, Kai Zhang, Xianyi Liu, Yun Li, Yu Liu, and Yuting Su</div> <div class="periodical"> <em>IEEE Internet of Things Journal</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=10286302" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/KaiZhang1228/DP2Net" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Nowadays, with the continuous development of information technology, the application scenarios of the Internet of Things (IoT) are progressively expanding to the social field, engendering widespread attention to the Social Internet of Things (SIoT). Personalized fashion recommendation that possesses the potential to establish social relationships between clothing and humans has substantially broadened the scope of the SIoT, particularly with the flourishing fashion industry and the ascent of smart home. Compared to conventional recommendations, fashion recommendation generally suggests a collection of items rather than individual pieces for users. Additionally, considering the public acceptance alongside the user-specific preference is reasonable for fashion recommendation, however, current methods often overlook the former. To comprehensively capture the public acceptance and the user-specific preference, we propose a dual preference perception network (DP2Net) for fashion recommendation. Firstly, a fashion corpus is constructed to facilitate the condensation of general taste, wherein adversarial learning and determinantal point process are leveraged to ensure representativeness and diversity of the corpus. Secondly, a user-general preference perception module is built based on a bottleneck transformer structure to generate aggregated representations for the corpus. Thirdly, a user-specific preference perception module is constructed to acquire collaborative representations of users and outfits by employing an attentive heterogeneous graph embedding. The final loss functions of two preference perception modules are constructed by combining the representations of users, outfits, and the corpus. Experiments on large-scale real-world datasets demonstrate the effectiveness of the proposed method.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="fan2023dual" class="col-sm-10"> <div class="title">Dual-domain Aligned Deep Hierarchical Matrix Factorization Method for Micro-video Multi-label Classification</div> <div class="author"> Fugui Fan, Yuting Su, Liqiang Nie, <em>Peiguang Jing</em>, Daozheng Hong, and Yu Liu</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="Jing2023style" class="col-sm-10"> <div class="title">StyleEDL: Style-Guided High-order Attention Network for Image Emotion Distribution Learning</div> <div class="author"> <em>Peiguang Jing</em>, Xianyi Liu, Ji Wang, Liqiang Nie, and Yuting Su</div> <div class="periodical"> <em>In Proceedings of ACM International Conference on Multimedia</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="/news/assets/pdf/" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/liuxianyi/StyleEDL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Emotion distribution learning has gained increasing attention with the tendency to express emotions through images. As for emotion ambiguity arising from humans’ subjectivity, substantial previous methods generally focused on learning appropriate representations from the holistic or significant part of images. However, they rarely consider establishing connections with the stylistic information although it can lead to a better understanding of images. In this paper, we propose a style-guided high-order attention network for image emotion distribution learning termed StyleEDL, which interactively learns stylistic-aware representations of images by exploring the hierarchical stylistic information of visual contents. Specifically, we consider exploring the intra- and inter-layer correlations among GRAM-based stylistic representations, and meanwhile exploit an adversary-constrained high-order attention mechanism to capture potential interactions between subtle visual parts. In addition, we introduce a stylistic graph convolutional network to dynamically generate the content-dependent emotion representations to benefit the final emotion distribution learning. Extensive experiments conducted on several benchmark datasets demonstrate the effectiveness of our proposed StyleEDL compared to state-of-the-art methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="li2023self" class="col-sm-10"> <div class="title">Self-supervised Deep Partial Adversarial Network for Micro-video Multimodal Classification</div> <div class="author"> Yun Li, Shuyi Liu, Xuejun Wang, and <em>Peiguang Jing</em> </div> <div class="periodical"> <em>Information Sciences</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025522014177" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/peiguangjing/SDMAN.git" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Micro-videos have gained popularity on various social media platforms because they provide a great medium for real-time storytelling. Although micro-videos can be naturally characterized by several modalities, for situations with uncertain missing modalities, a flexible multimodal representation learning framework that integrates complementary and consistent information has been difficult to develop. To better deal with the issue regarding incomplete modalities in multimodal micro-video classification, in this paper, we propose a self-supervised deep multimodal adversarial network (SDMAN) to learn comprehensive and robust micro-video representations. Specifically, we first consider a parallel multi-head attention (MHA) encoding module that simultaneously learns the representations of complete and incomplete modality groupings. We then present a multimodal self-supervised cycle generative adversarial network module, in which multiple generative adversarial networks are explored to transfer the information obtained from the complete modality grouping to the incomplete modality groupings. As a result, complementarity and consistency are mutually promoted among the modalities. Furthermore, experiments conducted on a large-scale micro-video dataset demonstrate that the SDMAN performs better than the state-of-the-art methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="lu2021learning" class="col-sm-10"> <div class="title">Learning Dual Low-rank Representation for Multi-label Micro-video Classification</div> <div class="author"> Wei Lu, Desheng Li, Liqiang Nie, <em>Peiguang Jing</em>, and Yuting Su</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="yin2023internet" class="col-sm-10"> <div class="title">Internet of Things for Diagnosis of Alzheimer’s Disease: A Multimodal Machine Learning Approach Based on Eye Movement Features</div> <div class="author"> Yunpeng Yin, Han Wang, Shuai Liu, Jinglin Sun, <em>Peiguang Jing</em>, and Yu Liu</div> <div class="periodical"> <em>IEEE Internet of Things Journal</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/spl/LuLJS23" class="col-sm-10"> <div class="title">A Multimodal Aggregation Network With Serial Self-Attention Mechanism for Micro-Video Multi-Label Classification</div> <div class="author"> Wei Lu, Jiaxin Lin, <em>Peiguang Jing</em>, and Yuting Su</div> <div class="periodical"> <em>IEEE Signal Processing Letters</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/abstract/document/10032700/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/GhostJxL/MANET" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Currently, micro-videos have attracted increasing attention due to their unique properties and great commercial value. Considering that micro-videos naturally incorporate multimodal information, a powerful representation method for distinct joint multimodal representations is essential for real applications. Inspired by the potential of attention neural network architectures over various tasks, we propose a multimodal aggregation network (MANET) with a serial self-attention mechanism to perform tasks of micro-video multi-label classification. Specifically, we first propose a parallel content-dependent graph neural networks (CDGNN) module, which explores category-related embeddings of micro-videos by disentangling category relations into modality-specific and modality-shared category dependency patterns. Then we introduce a serial self-attention (SSA) module to transmit the multimodal information in sequential order, in which an aggregation bottleneck is incorporated to better collect and condense the significant information. Experiments conducted on a large-scale multi-label micro-video dataset demonstrate that our proposed method has achieved competitive results compared with several state-of-the-art methods.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="10049142" class="col-sm-10"> <div class="title">Category-aware Multimodal Attention Network for Fashion Compatibility Modeling</div> <div class="author"> <em>Peiguang Jing</em>, Kai Cui, Weili Guan, Liqiang Nie, and Yuting Su</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tim/SunWWJL23" class="col-sm-10"> <div class="title">A Novel Integrated Eye-Tracking System With Stereo Stimuli for 3-D Gaze Estimation</div> <div class="author"> Jinglin Sun, Zhipeng Wu, Han Wang, <em>Peiguang Jing</em>, and Yu Liu</div> <div class="periodical"> <em>IEEE Transactions on Instrumentation and Measurement</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="sun2022novel" class="col-sm-10"> <div class="title">A Novel Deep Learning Approach for Diagnosing Alzheimer’s Disease Based on Eye-tracking Data</div> <div class="author"> Jinglin Sun, Yu Liu, Hao Wu, <em>Peiguang Jing</em>, and Yong Ji</div> <div class="periodical"> <em>Frontiers in Human Neuroscience</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/jvcir/Jin0J22" class="col-sm-10"> <div class="title">Video Frame Deletion Detection Based on Time-frequency Analysis</div> <div class="author"> Xiao Jin, Yuting Su, and <em>Peiguang Jing</em> </div> <div class="periodical"> <em>Journal of Visual Communication and Image Representation</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tamd/JinJWXS22" class="col-sm-10"> <div class="title">Visual Sentiment Classification via Low-Rank Regularization and Label Relaxation</div> <div class="author"> Xiao Jin, <em>Peiguang Jing</em>, Jiesheng Wu, Jing Xu, and Yuting Su</div> <div class="periodical"> <em>IEEE Transactions on Cognitive and Developmental Systems</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tcsv/LiuWNSJY22" class="col-sm-10"> <div class="title">Residual-Guided Multiscale Fusion Network for Bit-Depth Enhancement</div> <div class="author"> Jing Liu, Xin Wen, Weizhi Nie, Yuting Su, <em>Peiguang Jing</em>, and Xiaokang Yang</div> <div class="periodical"> <em>IEEE Transactions on Circuits Systtem and Video Technology</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tmm/JingZNYLS22" class="col-sm-10"> <div class="title">Tripartite Graph Regularized Latent Low-Rank Representation for Fashion Compatibility Prediction</div> <div class="author"> <em>Peiguang Jing</em>, Jing Zhang, Liqiang Nie, Shu Ye, Jing Liu, and Yuting Su</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="9672699" class="col-sm-10"> <div class="title">Exploiting Low-rank Latent Gaussian Graphical Model Estimation for Visual Sentiment Distribution</div> <div class="author"> Yuting Su, Wei Zhao, <em>Peiguang Jing</em>, and Liqiang Nie</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://ieeexplore.ieee.org/abstract/document/9672699/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://gitee.com/echozw/test-scggm.git" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Nowadays, an increasing number of applications and services encourages users to express their emotions via images openly. Different from traditional visual sentiment classification, visual sentiment distribution learning is to explore the overall distribution to present the relative importance of sentiment labels. Considering most relevant studies that failed to completely model correlation structures or explicitly applied to unknown instances, in this paper, we proposed a low-rank latent Gaussian graphical model estimation (LGGME) method to solve visual sentiment distribution learning tasks. The main characteristics of LGGME are three folds: 1) an integrated inverse covariance matrix whose parameters characterize the latent correlation structures between and within features and sentiments is estimated with a sparse Gaussian graphical model; 2) a multivariate normal assumption is assigned on the concatenated latent feature representations and the estimated sentiment distributions instead of the original observations for a reasonable surrogate; 3) the latent feature representations are projected from a low-rank subspace which is also available for unseen instances and the estimated sentiment distributions are evaluated by KL divergence to ensure a suitable setting for distribution learning. We further developed an effective optimization algorithm based on the alternating direction method of multipliers (ADMM) for our objective function. Experiment results conduced on three publicly available datasets demonstrate the superiority of our proposed method.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:conf/embc/LiSWNJZS22" class="col-sm-10"> <div class="title">EEG Emotion Recognition Based on Self-attention Dynamic Graph Neural Networks</div> <div class="author"> Chao Li, Yong Sheng, Haishuai Wang, Mingyue Niu, <em>Peiguang Jing</em>, Ziping Zhao, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Björn W. Schuller' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In In Proceedings of European Molecular Biology Conference</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/ijon/JingLLWS21" class="col-sm-10"> <div class="title">Joint Nuclear- and L21-norm Regularized Heterogeneous Tensor Decomposition for Robust Classification</div> <div class="author"> <em>Peiguang Jing</em>, Yaxin Li, Xinhui Li, Yuting Wu, and Yuting Su</div> <div class="periodical"> <em>Neurocomputing</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/isci/JingSLN21" class="col-sm-10"> <div class="title">Learning Robust Affinity Graph Representation for Multi-view Clustering</div> <div class="author"> <em>Peiguang Jing</em>, Yuting Su, Zhengnan Li, and Liqiang Nie</div> <div class="periodical"> <em>Information Sciences</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/isci/SuXHFZJ21" class="col-sm-10"> <div class="title">Deep Low-rank Matrix Factorization with Latent Correlation Estimation for Micro-video Multi-label Classification</div> <div class="author"> Yuting Su, Junyu Xu, Daozheng Hong, Fugui Fan, Jing Zhang, and <em>Peiguang Jing</em> </div> <div class="periodical"> <em>Information Sciences</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/spl/FanSJL21" class="col-sm-10"> <div class="title">A Dual Rank-Constrained Filter Pruning Approach for Convolutional Neural Networks</div> <div class="author"> Fugui Fan, Yuting Su, <em>Peiguang Jing</em>, and Wei Lu</div> <div class="periodical"> <em>IEEE Signal Processing Letters</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tmm/JingSNSLW21" class="col-sm-10"> <div class="title">Learning Low-Rank Sparse Representations With Robust Relationship Inference for Image Memorability Prediction</div> <div class="author"> <em>Peiguang Jing</em>, Yuechen Shang, Liqiang Nie, Yuting Su, Jing Liu, and Meng Wang</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tomccap/WangDJJSN21" class="col-sm-10"> <div class="title">Market2Dish: Health-aware Food Recommendation</div> <div class="author"> Wenjie Wang, Ling-Yu Duan, Hao Jiang, <em>Peiguang Jing</em>, Xuemeng Song, and Liqiang Nie</div> <div class="periodical"> <em>ACM Transactions on Multimedia Computing, Communications, and Applications</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:conf/icip/ChuFJL21" class="col-sm-10"> <div class="title">Joint Co-Attention And Co-Reconstruction Representation Learning For One-Shot Object Detection</div> <div class="author"> Jinghui Chu, Jiawei Feng, <em>Peiguang Jing</em>, and Wei Lu</div> <div class="periodical"> <em>In In Proceedings of IEEE International Conference on Image Processing</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/access/ZhangWLJS20" class="col-sm-10"> <div class="title">Low-Rank Regularized Multimodal Representation for Micro-Video Event Detection</div> <div class="author"> Jing Zhang, Yuting Wu, Jinghui Liu, <em>Peiguang Jing</em>, and Yuting Su</div> <div class="periodical"> <em>IEEE Access</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/mms/SuLBJ20" class="col-sm-10"> <div class="title">Predicting the Popularity of Micro-videos Via a Feature-Discrimination Transductive Model</div> <div class="author"> Yuting Su, Yang Li, Xu Bai, and <em>Peiguang Jing</em> </div> <div class="periodical"> <em>Multimedia Systems</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/mta/JingGBGS20" class="col-sm-10"> <div class="title">Single image super-resolution via low-rank tensor representation and hierarchical dictionary learning</div> <div class="author"> <em>Peiguang Jing</em>, Weili Guan, Xu Bai, Hongbin Guo, and Yuting Su</div> <div class="periodical"> <em>Multimedia Tools and Applications</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/spl/SuHLJ20" class="col-sm-10"> <div class="title">Low-Rank Regularized Deep Collaborative Matrix Factorization for Micro-Video Multi-Label Classification</div> <div class="author"> Yuting Su, Daozheng Hong, Yang Li, and <em>Peiguang Jing</em> </div> <div class="periodical"> <em>IEEE Signal Processing Letters</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tmm/JingYNLS20" class="col-sm-10"> <div class="title">Low-Rank Regularized Multi-Representation Learning for Fashion Compatibility Prediction</div> <div class="author"> <em>Peiguang Jing</em>, Shu Ye, Liqiang Nie, Jing Liu, and Yuting Su</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/corr/abs-2012-04886" class="col-sm-10"> <div class="title">DS-Net: Dynamic Spatiotemporal Network for Video Salient Object Detection</div> <div class="author"> Yuting Su, Weikang Wang, Jing Liu, <em>Peiguang Jing</em>, and Xiaokang Yang</div> <div class="periodical"> <em>CoRR</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/ijon/SuSLZJ19" class="col-sm-10"> <div class="title">Photo-realistic image bit-depth enhancement via residual transposed convolutional neural network</div> <div class="author"> Yuting Su, Wanning Sun, Jing Liu, Guangtao Zhai, and <em>Peiguang Jing</em> </div> <div class="periodical"> <em>Neurocomputing</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/iotj/LuFCJS19" class="col-sm-10"> <div class="title">Wearable Computing for Internet of Things: A Discriminant Approach for Human Activity Recognition</div> <div class="author"> Wei Lu, Fugui Fan, Jinghui Chu, <em>Peiguang Jing</em>, and Yuting Su</div> <div class="periodical"> <em>IEEE Internet of Things Journal</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/mta/ZhangLJLS19" class="col-sm-10"> <div class="title">Tensor-driven low-rank discriminant analysis for image set classification</div> <div class="author"> Jing Zhang, Zhengnan Li, <em>Peiguang Jing</em>, Ye Liu, and Yuting Su</div> <div class="periodical"> <em>Multimedia Tools and Applications</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/mta/ZhangSJLS19" class="col-sm-10"> <div class="title">A structure-transfer-driven temporal subspace clustering for video summarization</div> <div class="author"> Jing Zhang, Yue Shi, <em>Peiguang Jing</em>, Jing Liu, and Yuting Su</div> <div class="periodical"> <em>Multimedia Tools and Applications</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/sigpro/JingSLLN19" class="col-sm-10"> <div class="title">Low-rank regularized tensor discriminant representation for image set classification</div> <div class="author"> <em>Peiguang Jing</em>, Yuting Su, Zhengnan Li, Jing Liu, and Liqiang Nie</div> <div class="periodical"> <em>Signal Processing</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tcsv/JingSNGLW19" class="col-sm-10"> <div class="title">A Framework of Joint Low-Rank and Sparse Regression for Image Memorability Prediction</div> <div class="author"> <em>Peiguang Jing</em>, Yuting Su, Liqiang Nie, Huimin Gu, Jing Liu, and Meng Wang</div> <div class="periodical"> <em>IEEE Transactions on Circuits and Systems for Video Technology</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tcyb/JingSJZ19" class="col-sm-10"> <div class="title">High-Order Temporal Correlation Model Learning for Time-Series Prediction</div> <div class="author"> <em>Peiguang Jing</em>, Yuting Su, Xiao Jin, and Chengqian Zhang</div> <div class="periodical"> <em>IEEE Transations on Cybernetics</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tip/LiuSSJY19" class="col-sm-10"> <div class="title">BE-CALF: Bit-Depth Enhancement by Concatenating All Level Features of DNN</div> <div class="author"> Jing Liu, Wanning Sun, Yuting Su, <em>Peiguang Jing</em>, and Xiaokang Yang</div> <div class="periodical"> <em>IEEE Transactions on Image Processing</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tmm/LiuLSJY19" class="col-sm-10"> <div class="title">Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement</div> <div class="author"> Jing Liu, Pingping Liu, Yuting Su, <em>Peiguang Jing</em>, and Xiaokang Yang</div> <div class="periodical"> <em>IEEE Transactions on Mutlimedia</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:conf/mm/DongSFJXN19" class="col-sm-10"> <div class="title">Personalized Capsule Wardrobe Creation with Garment and User Modeling</div> <div class="author"> Xue Dong, Xuemeng Song, Fuli Feng, <em>Peiguang Jing</em>, Xin-Shun Xu, and Liqiang Nie</div> <div class="periodical"> <em>In In Proceedings of ACM International Conference on Multimedia</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/access/0002SJYS18" class="col-sm-10"> <div class="title">Improving Bit-Depth Expansion via Context-Aware MMSE Optimization (CAMO)</div> <div class="author"> Jing Liu, Wanning Sun, <em>Peiguang Jing</em>, Jiexiao Yu, and Yuting Su</div> <div class="periodical"> <em>IEEE Access</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/access/JinSZWJW18" class="col-sm-10"> <div class="title">Sparsity-Based Image Inpainting Detection via Canonical Correlation Analysis With Low-Rank Constraints</div> <div class="author"> Xiao Jin, Yuting Su, Liang Zou, Yongwei Wang, <em>Peiguang Jing</em>, and Z. Jane Wang</div> <div class="periodical"> <em>IEEE Access</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/access/JinJS18" class="col-sm-10"> <div class="title">AMFNet: An Adversarial Network for Median Filtering Detection</div> <div class="author"> Xiao Jin, <em>Peiguang Jing</em>, and Yuting Su</div> <div class="periodical"> <em>IEEE Access</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/ijon/JingSXZ18" class="col-sm-10"> <div class="title">HyperSSR: A hypergraph based semi-supervised ranking method for visual search reranking</div> <div class="author"> <em>Peiguang Jing</em>, Yuting Su, Chuan-Zhong Xu, and Luming Zhang</div> <div class="periodical"> <em>Neurocomputing</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/ijon/ChuGSJ18" class="col-sm-10"> <div class="title">Towards a sparse low-rank regression model for memorability prediction of images</div> <div class="author"> Jinghui Chu, Huimin Gu, Yuting Su, and <em>Peiguang Jing</em> </div> <div class="periodical"> <em>Neurocomputing</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/jvcir/SuBLJZL18" class="col-sm-10"> <div class="title">Graph regularized low-rank tensor representation for feature selection</div> <div class="author"> Yuting Su, Xu Bai, Wu Li, <em>Peiguang Jing</em>, Jing Zhang, and Jing Liu</div> <div class="periodical"> <em>Journal of Visual Communication and Image Representation</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/jvcir/LiuSJLS18" class="col-sm-10"> <div class="title">Low-rank regularized multi-view inverse-covariance estimation for visual sentiment distribution prediction</div> <div class="author"> Anan Liu, Yingdi Shi, <em>Peiguang Jing</em>, Jing Liu, and Yuting Su</div> <div class="periodical"> <em>Journal of Visual Communication and Image Representation </em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/mta/JinSZZJS18" class="col-sm-10"> <div class="title">Video logo removal detection based on sparse representation</div> <div class="author"> Xiao Jin, Yuting Su, Liang Zou, Chengqian Zhang, <em>Peiguang Jing</em>, and Xuemeng Song</div> <div class="periodical"> <em>Multimedia Tools and Applications</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/sigpro/LiuSJ0S18" class="col-sm-10"> <div class="title">Structured low-rank inverse-covariance estimation for visual sentiment distribution prediction</div> <div class="author"> Anan Liu, Yingdi Shi, <em>Peiguang Jing</em>, Jing Liu, and Yuting Su</div> <div class="periodical"> <em>Signal Processing</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/spl/ZhangLJLS18" class="col-sm-10"> <div class="title">Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering</div> <div class="author"> Jing Zhang, Xinhui Li, <em>Peiguang Jing</em>, Jing Liu, and Yuting Su</div> <div class="periodical"> <em>IEEE Signal Processing Letters</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tkde/JingSNBLW18" class="col-sm-10"> <div class="title">Low-Rank Multi-View Embedding Learning for Micro-Video Popularity Prediction</div> <div class="author"> <em>Peiguang Jing</em>, Yuting Su, Liqiang Nie, Xu Bai, Jing Liu, and Meng Wang</div> <div class="periodical"> <em>IEEE Transaction on Knowledge and Data Engineering</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/mta/SuWJX17" class="col-sm-10"> <div class="title">A spatial-temporal iterative tensor decomposition technique for action and gesture recognition</div> <div class="author"> Yuting Su, Haiyi Wang, <em>Peiguang Jing</em>, and Chuan-Zhong Xu</div> <div class="periodical"> <em>Multimedia Tools and Applications</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tcyb/ZhangJSZS17" class="col-sm-10"> <div class="title">SnapVideo: Personalized Video Generation for a Sightseeing Trip</div> <div class="author"> Luming Zhang, <em>Peiguang Jing</em>, Yuting Su, Chao Zhang, and Ling Shao</div> <div class="periodical"> <em>IEEE Transactions on Cybernetics</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tmm/JingSNG17" class="col-sm-10"> <div class="title">Predicting Image Memorability Through Adaptive Transfer Learning From External Sources</div> <div class="author"> <em>Peiguang Jing</em>, Yuting Su, Liqiang Nie, and Huimin Gu</div> <div class="periodical"> <em>IEEE Transactions on Multimedia</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/ijon/JingJYZ16" class="col-sm-10"> <div class="title">Visual search reranking with RElevant Local Discriminant Analysis</div> <div class="author"> <em>Peiguang Jing</em>, Zhong Ji, Yunlong Yu, and Zhongfei Zhang</div> <div class="periodical"> <em>Neurocomputing</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/jvcir/QiJWN16" class="col-sm-10"> <div class="title">Quality biased multimedia data retrieval in microblogs</div> <div class="author"> Shuhan Qi, <em>Peiguang Jing</em>, Xuan Wang, and Liqiang Nie</div> <div class="periodical"> <em>Journal of Visual Communication and Image Representation</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/spl/ZhangXJZS16" class="col-sm-10"> <div class="title">A Tensor-Driven Temporal Correlation Model for Video Sequence Classification</div> <div class="author"> Jing Zhang, Chuan-Zhong Xu, <em>Peiguang Jing</em>, Chengqian Zhang, and Yuting Su</div> <div class="periodical"> <em>IEEE Signal Processing Letters</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2013</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/ijon/JiJYSL13" class="col-sm-10"> <div class="title">Ranking Fisher discriminant analysis</div> <div class="author"> Zhong Ji, <em>Peiguang Jing</em>, Tianshi Yu, Yuting Su, and Changshu Liu</div> <div class="periodical"> <em>Neurocomputing</em>, 2013 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/sigpro/JiJSP13" class="col-sm-10"> <div class="title">Rank canonical correlation analysis and its application in visual search reranking</div> <div class="author"> Zhong Ji, <em>Peiguang Jing</em>, Yuting Su, and Yanwei Pang</div> <div class="periodical"> <em>Signal Processing</em>, 2013 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-0 abbr"></div> <div id="DBLP:journals/tnn/PangJJL13" class="col-sm-10"> <div class="title">Ranking Graph Embedding for Learning to Rerank</div> <div class="author"> Yanwei Pang, Zhong Ji, <em>Peiguang Jing</em>, and Xuelong Li</div> <div class="periodical"> <em>IEEE Transactions on Neural Networks and Learning Systems </em>, 2013 </div> <div class="periodical"> </div> <div class="links"> </div> <div class="badges"> </div> </div> </div> </li> </ol> <h2 class="year">2012</h2> <ol class="bibliography"></ol> <h2 class="year">2011</h2> <ol class="bibliography"></ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2024 Peiguang Jing . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: May 26, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/news/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/news/assets/js/zoom.js"></script> <script defer src="/news/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>