@article{luvmenet,
  author={Lu, Wei and Zhai, Yujia and Han, Jiaze and Jing, Peiguang and Liu, Yu and Su, Yuting},
  journal={IEEE Transactions on Multimedia}, 
  title={VMemNet: A Deep Collaborative Spatial-Temporal Network With Attention Representation for Video Memorability Prediction}, 
  year={2023},
  pages={1-12},
  selected  = {true},  
  pdf={https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10298788},
  code      = {https://github.com/accelerate20000/VMemNet},
  abstract={Video memorability measures the degree to which a video is remembered by different viewers and has shown great potential in various 
contexts, including advertising, education, and health care. While extensive research has been conducted on image memorability, the study of 
video memorability is still in its early stages. Existing methods in this field primarily focus on coarse-grained spatial feature representation 
and decision fusion strategies, overlooking the crucial interactions between spatial and temporal domains. Therefore, we propose an end-to-end 
collaborative spatial-temporal network called VMemNet, which incorporates targeted attention mechanisms and intermediation fusion strategies. 
This enables VMemNet to capture the intricate relationships between spatial and temporal information and uncover more elements of memorability 
within video visual features. VMemNet integrates spatially and semantically guided attention modules into a dual-stream network architecture, 
allowing it to simultaneously capture static local cues and dynamic global cues in videos. Specifically, the spatial attention module is used 
to aggregate more memorable elements from spatial locations, and the semantically guided attention module is used to achieve semantic alignment 
and intermediate fusion of the local and global cues. In addition, two types of loss functions with complementary decision rules are associated 
with the corresponding attention modules to guide the training process of the proposed network. Experimental results obtained on a publicly available dataset verify that the proposed 
VMemNet approach outperforms all current single- and multi-modal methods in terms of video memorability prediction.}
}
@article{jing2023dual,
  title={Dual Preference Perception Network for Fashion Recommendation in the Social Internet of Things},
  author={Jing, Peiguang and Zhang, Kai and Liu, Xianyi and Li, Yun and Liu, Yu and Su, Yuting},
  journal={IEEE Internet of Things Journal},
  year={2023},
  selected  = {true},  
  pdf       = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10286302},
  code      = {https://github.com/KaiZhang1228/DP2Net},
  abstract ={Nowadays, with the continuous development of information technology, the application scenarios of the Internet of Things (IoT) are 
progressively expanding to the social field, engendering widespread attention to the Social Internet of Things (SIoT). Personalized fashion 
recommendation that possesses the potential to establish social relationships between clothing and humans has substantially broadened the 
scope of the SIoT, particularly with the flourishing fashion industry and the ascent of smart home. Compared to conventional recommendations, 
fashion recommendation generally suggests a collection of items rather than individual pieces for users. Additionally, considering the public 
acceptance alongside the user-specific preference is reasonable for fashion recommendation, however, current methods often overlook the former. 
To comprehensively capture the public acceptance and the user-specific preference, we propose a dual preference perception network (DP2Net) for 
fashion recommendation. Firstly, a fashion corpus is constructed to facilitate the condensation of general taste, wherein adversarial learning 
and determinantal point process are leveraged to ensure representativeness and diversity of the corpus. Secondly, a user-general preference 
perception module is built based on a bottleneck transformer structure to generate aggregated representations for the corpus. Thirdly, a 
user-specific preference perception module is constructed to acquire collaborative representations of users and outfits by employing an attentive 
heterogeneous graph embedding. The final loss functions of two preference perception modules are constructed by combining the representations of 
users, outfits, and the corpus. Experiments on large-scale real-world datasets demonstrate the effectiveness of the proposed method.}
}
@article{fan2023dual,
  title={Dual-domain Aligned Deep Hierarchical Matrix Factorization Method for Micro-video Multi-label Classification},
  author={Fan, Fugui and Su, Yuting and Nie, Liqiang and Jing, Peiguang and Hong, Daozheng and Liu, Yu},
  journal ={IEEE Transactions on Multimedia},
  volume={},
  pages={},
  year={2023},
  selected  = {true},  
}

@inproceedings{Jing2023style,
  title={StyleEDL: Style-Guided High-order Attention Network for Image Emotion Distribution Learning},
  author={Peiguang Jing and Xianyi Liu and Ji Wang and Liqiang Nie and Yuting Su},
  booktitle ={Proceedings of {ACM} International Conference on Multimedia},
  volume={},
  pages={},
  year={2023},
  selected  = {true},  
  pdf       = {},
  code      = {https://github.com/liuxianyi/StyleEDL},
  abstract ={Emotion distribution learning has gained increasing attention with the tendency to express emotions through images. As for emotion ambiguity arising from humans’ subjectivity, 
substantial previous methods generally focused on learning appropriate representations from the holistic or significant part of 
images. However, they rarely consider establishing connections with the stylistic information although it can lead to a better 
understanding of images. In this paper, we propose a style-guided high-order attention network for image emotion distribution 
learning termed StyleEDL, which interactively learns stylistic-aware representations of images by exploring the hierarchical 
stylistic information of visual contents. Specifically, we consider exploring the intra- and inter-layer correlations among 
GRAM-based stylistic representations, and meanwhile exploit an adversary-constrained high-order attention mechanism to capture 
potential interactions between subtle visual parts. In addition, we introduce a stylistic graph convolutional network to dynamically 
generate the content-dependent emotion representations to benefit the final emotion distribution learning. Extensive experiments conducted 
on several benchmark datasets demonstrate the effectiveness of our proposed StyleEDL compared to state-of-the-art methods.}
}
@article{sun2022novel,
  title={A Novel Deep Learning Approach for Diagnosing Alzheimer's Disease Based on Eye-tracking Data},
  author={Sun, Jinglin and Liu, Yu and Wu, Hao and Jing, Peiguang and Ji, Yong},
  journal={Frontiers in Human Neuroscience},
  year={2022},
}

@article{li2023self,
  title={Self-supervised Deep Partial Adversarial Network for Micro-video Multimodal Classification},
  author={Li, Yun and Liu, Shuyi and Wang, Xuejun and Jing, Peiguang},
  journal={Information Sciences},
  volume={630},
  pages={356--369},
  year={2023},
  selected  = {true},  
  pdf       = {https://www.sciencedirect.com/science/article/abs/pii/S0020025522014177},
  code      = {https://github.com/peiguangjing/SDMAN.git},
  abstract ={Micro-videos have gained popularity on various social media platforms because they provide a great medium for real-time storytelling. Although micro-videos can be naturally characterized by several modalities, for situations with uncertain missing modalities, a flexible multimodal representation learning framework that integrates complementary and consistent information has been difficult to develop. To better deal with the issue regarding incomplete modalities in multimodal micro-video classification, in this paper, we propose a self-supervised deep multimodal adversarial network (SDMAN) to learn comprehensive and robust micro-video representations. Specifically, we first consider a parallel multi-head attention (MHA) encoding module that simultaneously learns the representations of complete and incomplete modality groupings. We then present a multimodal self-supervised cycle generative adversarial network module, in which multiple generative adversarial networks are explored to transfer the information obtained from the complete modality grouping to the incomplete modality groupings. As a result, complementarity and consistency are mutually promoted among the modalities. Furthermore, experiments conducted on a large-scale micro-video dataset demonstrate that the SDMAN performs better than the state-of-the-art methods.}
}

@article{lu2021learning,
  title={Learning Dual Low-rank Representation for Multi-label Micro-video Classification},
  author={Lu, Wei and Li, Desheng and Nie, Liqiang and Jing, Peiguang and Su, Yuting},
  journal={IEEE Transactions on Multimedia},
  year={2023},
  selected  = {true},  
}

@article{yin2023internet,
  title={Internet of Things for Diagnosis of Alzheimer’s Disease: A Multimodal Machine Learning Approach Based on Eye Movement Features},
  author={Yin, Yunpeng and Wang, Han and Liu, Shuai and Sun, Jinglin and Jing, Peiguang and Liu, Yu},
  journal={IEEE Internet of Things Journal},
  year={2023},
  selected  = {true},  
}

@article{DBLP:journals/spl/LuLJS23,
  author    = {Wei Lu and
               Jiaxin Lin and
               Peiguang Jing and
               Yuting Su},
  title     = {A Multimodal Aggregation Network With Serial Self-Attention Mechanism for Micro-Video Multi-Label Classification},
  journal   = {IEEE Signal Processing Letters},
  volume    = {30},
  pages     = {60--64},
  year      = {2023},
  selected  = {true},
  pdf       = {https://ieeexplore.ieee.org/abstract/document/10032700/},
  code      = {https://github.com/GhostJxL/MANET},
  abstract  = {Currently, micro-videos have attracted increasing attention due to their unique properties and great commercial value. Considering that micro-videos naturally incorporate multimodal information, a powerful representation method for distinct joint multimodal representations is essential for real applications. Inspired by the potential of attention neural network architectures over various tasks, we propose a multimodal aggregation network (MANET) with a serial self-attention mechanism to perform tasks of micro-video multi-label classification. Specifically, we first propose a parallel content-dependent graph neural networks (CDGNN) module, which explores category-related embeddings of micro-videos by disentangling category relations into modality-specific and modality-shared category dependency patterns. Then we introduce a serial self-attention (SSA) module to transmit the multimodal information in sequential order, in which an aggregation bottleneck is incorporated to better collect and condense the significant information. Experiments conducted on a large-scale multi-label micro-video dataset demonstrate that our proposed method has achieved competitive results compared with several state-of-the-art methods.}
}


@ARTICLE{10049142,
  author={Jing, Peiguang and Cui, Kai and Guan, Weili and Nie, Liqiang and Su, Yuting},
  journal={IEEE Transactions on Multimedia}, 
  title={Category-aware Multimodal Attention Network for Fashion Compatibility Modeling}, 
  year={2023},
  pages={1-12},
  selected={true},
}

@article{DBLP:journals/tim/SunWWJL23,
  author    = {Jinglin Sun and
               Zhipeng Wu and
               Han Wang and
               Peiguang Jing and
               Yu Liu},
  title     = {A Novel Integrated Eye-Tracking System With Stereo Stimuli for 3-D Gaze Estimation},
  journal   = {{IEEE} Transactions on Instrumentation and Measurement},
  volume    = {72},
  pages     = {1--15},
  year      = {2023},
  selected={true},
}

@article{DBLP:journals/jvcir/Jin0J22,
  author    = {Xiao Jin and
               Yuting Su and
               Peiguang Jing},
  title     = {Video Frame Deletion Detection Based on Time-frequency Analysis},
  journal   = {Journal of Visual Communication and Image Representation},
  volume    = {83},
  pages     = {103436},
  year      = {2022},
}

@article{DBLP:journals/tamd/JinJWXS22,
  author    = {Xiao Jin and
               Peiguang Jing and
               Jiesheng Wu and
               Jing Xu and
               Yuting Su},
  title     = {Visual Sentiment Classification via Low-Rank Regularization and Label Relaxation},
  journal   = {{IEEE}  Transactions on Cognitive and Developmental Systems},
  volume    = {14},
  number    = {4},
  pages     = {1678--1690},
  year      = {2022},
  selected={true},
}

@article{DBLP:journals/tcsv/LiuWNSJY22,
  author    = {Jing Liu and
               Xin Wen and
               Weizhi Nie and
               Yuting Su and
               Peiguang Jing and
               Xiaokang Yang},
  title     = {Residual-Guided Multiscale Fusion Network for Bit-Depth Enhancement},
  journal   = {{IEEE} Transactions on Circuits Systtem and Video Technology},
  volume    = {32},
  number    = {5},
  pages     = {2773--2786},
  year      = {2022},
  selected={true},
}

@article{DBLP:journals/tmm/JingZNYLS22,
  author    = {Peiguang Jing and
               Jing Zhang and
               Liqiang Nie and
               Shu Ye and
               Jing Liu and
               Yuting Su},
  title     = {Tripartite Graph Regularized Latent Low-Rank Representation for Fashion Compatibility Prediction},
  journal   = {IEEE Transactions on Multimedia},
  volume    = {24},
  pages     = {1277--1287},
  year      = {2022},
  selected={true},
 }

@ARTICLE{9672699,
  author={Su, Yuting and Zhao, Wei and Jing, Peiguang and Nie, Liqiang},
  journal={IEEE Transactions on Multimedia}, 
  title={Exploiting Low-rank Latent Gaussian Graphical Model Estimation for Visual Sentiment Distribution}, 
  year={2022},
  selected={true},
  pdf       = {https://ieeexplore.ieee.org/abstract/document/9672699/},
  code      = {https://gitee.com/echozw/test-scggm.git},
  abstract  ={Nowadays, an increasing number of applications and services encourages users to express their emotions via images openly. Different from traditional visual sentiment classification, visual sentiment distribution learning is to explore the overall distribution to present the relative importance of sentiment labels. Considering most relevant studies that failed to completely model correlation structures or explicitly applied to unknown instances, in this paper, we proposed a low-rank latent Gaussian graphical model estimation (LGGME) method to solve visual sentiment distribution learning tasks. The main characteristics of LGGME are three folds: 1) an integrated inverse covariance matrix whose parameters characterize the latent correlation structures between and within features and sentiments is estimated with a sparse Gaussian graphical model; 2) a multivariate normal assumption is assigned on the concatenated latent feature representations and the estimated sentiment distributions instead of the original observations for a reasonable surrogate; 3) the latent feature representations are projected from a low-rank subspace which is also available for unseen instances and the estimated sentiment distributions are evaluated by KL divergence to ensure a suitable setting for distribution learning. We further developed an effective optimization algorithm based on the alternating direction method of multipliers (ADMM) for our objective function. Experiment results conduced on three publicly available datasets demonstrate the superiority of our proposed method.}
}

@inproceedings{DBLP:conf/embc/LiSWNJZS22,
  author    = {Chao Li and
               Yong Sheng and
               Haishuai Wang and
               Mingyue Niu and
               Peiguang Jing and
               Ziping Zhao and
               Bj{\"{o}}rn W. Schuller},
  title     = {{EEG} Emotion Recognition Based on Self-attention Dynamic Graph Neural
               Networks},
  booktitle = {In Proceedings of European Molecular Biology Conference},
  pages     = {292--296},
  year      = {2022},
}

@article{DBLP:journals/ijon/JingLLWS21,
  author    = {Peiguang Jing and
               Yaxin Li and
               Xinhui Li and
               Yuting Wu and
               Yuting Su},
  title     = {Joint Nuclear- and L21-norm Regularized Heterogeneous Tensor Decomposition for Robust Classification},
  journal   = {Neurocomputing},
  volume    = {464},
  pages     = {317--329},
  year      = {2021},
}

@article{DBLP:journals/isci/JingSLN21,
  author    = {Peiguang Jing and
               Yuting Su and
               Zhengnan Li and
               Liqiang Nie},
  title     = {Learning Robust Affinity Graph Representation for Multi-view Clustering},
  journal   = {Information Sciences},
  volume    = {544},
  pages     = {155--167},
  year      = {2021},
  selected={true},
}

@article{DBLP:journals/isci/SuXHFZJ21,
  author    = {Yuting Su and
               Junyu Xu and
               Daozheng Hong and
               Fugui Fan and
               Jing Zhang and
               Peiguang Jing},
  title     = {Deep Low-rank Matrix Factorization with Latent Correlation Estimation for Micro-video Multi-label Classification},
  journal   = {Information Sciences},
  volume    = {575},
  pages     = {587--598},
  year      = {2021},
  selected={true},
}

@article{DBLP:journals/spl/FanSJL21,
  author    = {Fugui Fan and
               Yuting Su and
               Peiguang Jing and
               Wei Lu},
  title     = {A Dual Rank-Constrained Filter Pruning Approach for Convolutional
               Neural Networks},
  journal   = {{IEEE} Signal Processing Letters},
  volume    = {28},
  pages     = {1734--1738},
  year      = {2021},
  selected={true},
}

@article{DBLP:journals/tmm/JingSNSLW21,
  author    = {Peiguang Jing and
               Yuechen Shang and
               Liqiang Nie and
               Yuting Su and
               Jing Liu and
               Meng Wang},
  title     = {Learning Low-Rank Sparse Representations With Robust Relationship Inference for Image Memorability Prediction},
  journal   = {{IEEE} Transactions on Multimedia},
  volume    = {23},
  pages     = {2259--2272},
  year      = {2021},
  selected={true},
}

@article{DBLP:journals/tomccap/WangDJJSN21,
  author    = {Wenjie Wang and
               Ling{-}Yu Duan and
               Hao Jiang and
               Peiguang Jing and
               Xuemeng Song and
               Liqiang Nie},
  title     = {Market2Dish: Health-aware Food Recommendation},
  journal   = {{ACM} Transactions on Multimedia Computing, Communications, and Applications},
  volume    = {17},
  number    = {1},
  pages     = {33:1--33:19},
  year      = {2021},
  selected={true},
}

@inproceedings{DBLP:conf/icip/ChuFJL21,
  author    = {Jinghui Chu and
               Jiawei Feng and
               Peiguang Jing and
               Wei Lu},
  title     = {Joint Co-Attention And Co-Reconstruction Representation Learning For One-Shot Object Detection},
  booktitle = {In Proceedings of IEEE International Conference on Image Processing},
  pages     = {2229--2233},
  year      = {2021},
}

@article{DBLP:journals/access/ZhangWLJS20,
  author    = {Jing Zhang and
               Yuting Wu and
               Jinghui Liu and
               Peiguang Jing and
               Yuting Su},
  title     = {Low-Rank Regularized Multimodal Representation for Micro-Video Event Detection},
  journal   = {{IEEE} Access},
  volume    = {8},
  pages     = {87266--87274},
  year      = {2020},
}

@article{DBLP:journals/mms/SuLBJ20,
  author    = {Yuting Su and
               Yang Li and
               Xu Bai and
               Peiguang Jing},
  title     = {Predicting the Popularity of Micro-videos Via a Feature-Discrimination Transductive Model},
  journal   = {Multimedia Systems},
  volume    = {26},
  number    = {5},
  pages     = {519--534},
  year      = {2020},
}

@article{DBLP:journals/mta/JingGBGS20,
  author    = {Peiguang Jing and
               Weili Guan and
               Xu Bai and
               Hongbin Guo and
               Yuting Su},
  title     = {Single image super-resolution via low-rank tensor representation and hierarchical dictionary learning},
  journal   = {Multimedia Tools and Applications},
  volume    = {79},
  number    = {17-18},
  pages     = {11767--11785},
  year      = {2020},
}

@article{DBLP:journals/spl/SuHLJ20,
  author    = {Yuting Su and
               Daozheng Hong and
               Yang Li and
               Peiguang Jing},
  title     = {Low-Rank Regularized Deep Collaborative Matrix Factorization for Micro-Video Multi-Label Classification},
  journal   = {{IEEE} Signal Processing Letters},
  volume    = {27},
  pages     = {740--744},
  year      = {2020},
  selected={true},
}

@article{DBLP:journals/tmm/JingYNLS20,
  author    = {Peiguang Jing and
               Shu Ye and
               Liqiang Nie and
               Jing Liu and
               Yuting Su},
  title     = {Low-Rank Regularized Multi-Representation Learning for Fashion Compatibility Prediction},
  journal   = {{IEEE} Transactions on Multimedia},
  volume    = {22},
  number    = {6},
  pages     = {1555--1566},
  year      = {2020},
  selected={true},
}

@article{DBLP:journals/corr/abs-2012-04886,
  author    = {Yuting Su and
               Weikang Wang and
               Jing Liu and
               Peiguang Jing and
               Xiaokang Yang},
  title     = {DS-Net: Dynamic Spatiotemporal Network for Video Salient Object Detection},
  journal   = {CoRR},
  volume    = {abs/2012.04886},
  year      = {2020},
}

@article{DBLP:journals/ijon/SuSLZJ19,
  author    = {Yuting Su and
               Wanning Sun and
               Jing Liu and
               Guangtao Zhai and
               Peiguang Jing},
  title     = {Photo-realistic image bit-depth enhancement via residual transposed convolutional neural network},
  journal   = {Neurocomputing},
  volume    = {347},
  pages     = {200--211},
  year      = {2019},
}

@article{DBLP:journals/iotj/LuFCJS19,
  author    = {Wei Lu and
               Fugui Fan and
               Jinghui Chu and
               Peiguang Jing and
               Yuting Su},
  title     = {Wearable Computing for Internet of Things: {A} Discriminant Approach
               for Human Activity Recognition},
  journal   = {{IEEE} Internet of Things Journal},
  volume    = {6},
  number    = {2},
  pages     = {2749--2759},
  year      = {2019},
  selected={true},
}

@article{DBLP:journals/mta/ZhangLJLS19,
  author    = {Jing Zhang and
               Zhengnan Li and
               Peiguang Jing and
               Ye Liu and
               Yuting Su},
  title     = {Tensor-driven low-rank discriminant analysis for image set classification},
  journal   = {Multimedia Tools and Applications},
  volume    = {78},
  number    = {4},
  pages     = {4001--4020},
  year      = {2019},
}

@article{DBLP:journals/mta/ZhangSJLS19,
  author    = {Jing Zhang and
               Yue Shi and
               Peiguang Jing and
               Jing Liu and
               Yuting Su},
  title     = {A structure-transfer-driven temporal subspace clustering for video summarization},
  journal   = {Multimedia Tools and Applications},
  volume    = {78},
  number    = {17},
  pages     = {24123--24145},
  year      = {2019},
}

@article{DBLP:journals/sigpro/JingSLLN19,
  author    = {Peiguang Jing and
               Yuting Su and
               Zhengnan Li and
               Jing Liu and
               Liqiang Nie},
  title     = {Low-rank regularized tensor discriminant representation for image set classification},
  journal   = {Signal Processing},
  volume    = {156},
  pages     = {62--70},
  year      = {2019},
  selected={true},
}

@article{DBLP:journals/tcsv/JingSNGLW19,
  author    = {Peiguang Jing and
               Yuting Su and
               Liqiang Nie and
               Huimin Gu and
               Jing Liu and
               Meng Wang},
  title     = {A Framework of Joint Low-Rank and Sparse Regression for Image Memorability
               Prediction},
  journal   = {{IEEE} Transactions on Circuits and Systems for Video Technology},
  volume    = {29},
  number    = {5},
  pages     = {1296--1309},
  year      = {2019},
  selected={true},
}

@article{DBLP:journals/tcyb/JingSJZ19,
  author    = {Peiguang Jing and
               Yuting Su and
               Xiao Jin and
               Chengqian Zhang},
  title     = {High-Order Temporal Correlation Model Learning for Time-Series Prediction},
  journal   = {{IEEE} Transations on  Cybernetics},
  volume    = {49},
  number    = {6},
  pages     = {2385--2397},
  year      = {2019},
  selected={true},
}

@article{DBLP:journals/tip/LiuSSJY19,
  author    = {Jing Liu and
               Wanning Sun and
               Yuting Su and
               Peiguang Jing and
               Xiaokang Yang},
  title     = {{BE-CALF:} Bit-Depth Enhancement by Concatenating All Level Features
               of {DNN}},
  journal   = {{IEEE} Transactions on Image Processing},
  volume    = {28},
  number    = {10},
  pages     = {4926--4940},
  year      = {2019},
  selected={true},
}

@article{DBLP:journals/tmm/LiuLSJY19,
  author    = {Jing Liu and
               Pingping Liu and
               Yuting Su and
               Peiguang Jing and
               Xiaokang Yang},
  title     = {Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth
               Enhancement},
  journal   = {{IEEE} Transactions on Mutlimedia},
  volume    = {21},
  number    = {9},
  pages     = {2397--2406},
  year      = {2019},
  selected={true},
}

@inproceedings{DBLP:conf/mm/DongSFJXN19,
  author    = {Xue Dong and
               Xuemeng Song and
               Fuli Feng and
               Peiguang Jing and
               Xin{-}Shun Xu and
               Liqiang Nie},
  title     = {Personalized Capsule Wardrobe Creation with Garment and User Modeling},
  booktitle = {In Proceedings of  {ACM} International Conference on Multimedia},
  pages     = {302--310},
  year      = {2019},
  selected={true},
}

@article{DBLP:journals/access/0002SJYS18,
  author    = {Jing Liu and
               Wanning Sun and
               Peiguang Jing and
               Jiexiao Yu and
               Yuting Su},
  title     = {Improving Bit-Depth Expansion via Context-Aware {MMSE} Optimization
               {(CAMO)}},
  journal   = {{IEEE} Access},
  volume    = {6},
  pages     = {46396--46406},
  year      = {2018},
}

@article{DBLP:journals/access/JinSZWJW18,
  author    = {Xiao Jin and
               Yuting Su and
               Liang Zou and
               Yongwei Wang and
               Peiguang Jing and
               Z. Jane Wang},
  title     = {Sparsity-Based Image Inpainting Detection via Canonical Correlation Analysis With Low-Rank Constraints},
  journal   = {{IEEE} Access},
  volume    = {6},
  pages     = {49967--49978},
  year      = {2018},
}

@article{DBLP:journals/access/JinJS18,
  author    = {Xiao Jin and
               Peiguang Jing and
               Yuting Su},
  title     = {AMFNet: An Adversarial Network for Median Filtering Detection},
  journal   = {{IEEE} Access},
  volume    = {6},
  pages     = {50459--50467},
  year      = {2018},
}

@article{DBLP:journals/ijon/JingSXZ18,
  author    = {Peiguang Jing and
               Yuting Su and
               Chuan{-}Zhong Xu and
               Luming Zhang},
  title     = {HyperSSR: {A} hypergraph based semi-supervised ranking method for visual search reranking},
  journal   = {Neurocomputing},
  volume    = {274},
  pages     = {50--57},
  year      = {2018},
}

@article{DBLP:journals/ijon/ChuGSJ18,
  author    = {Jinghui Chu and
               Huimin Gu and
               Yuting Su and
               Peiguang Jing},
  title     = {Towards a sparse low-rank regression model for memorability prediction
               of images},
  journal   = {Neurocomputing},
  volume    = {321},
  pages     = {357--368},
  year      = {2018},
}

@article{DBLP:journals/jvcir/SuBLJZL18,
  author    = {Yuting Su and
               Xu Bai and
               Wu Li and
               Peiguang Jing and
               Jing Zhang and
               Jing Liu},
  title     = {Graph regularized low-rank tensor representation for feature selection},
  journal   = {Journal of Visual Communication and Image Representation},
  volume    = {56},
  pages     = {234--244},
  year      = {2018},
}

@article{DBLP:journals/jvcir/LiuSJLS18,
  author    = {Anan Liu and
               Yingdi Shi and
               Peiguang Jing and
               Jing Liu and
               Yuting Su},
  title     = {Low-rank regularized multi-view inverse-covariance estimation for
               visual sentiment distribution prediction},
  journal   = {Journal of Visual Communication and Image Representation },
  volume    = {57},
  pages     = {243--252},
  year      = {2018},
}

@article{DBLP:journals/mta/JinSZZJS18,
  author    = {Xiao Jin and
               Yuting Su and
               Liang Zou and
               Chengqian Zhang and
               Peiguang Jing and
               Xuemeng Song},
  title     = {Video logo removal detection based on sparse representation},
  journal   = {Multimedia  Tools and Applications},
  volume    = {77},
  number    = {22},
  pages     = {29303--29322},
  year      = {2018},
}

@article{DBLP:journals/sigpro/LiuSJ0S18,
  author    = {Anan Liu and
               Yingdi Shi and
               Peiguang Jing and
               Jing Liu and
               Yuting Su},
  title     = {Structured low-rank inverse-covariance estimation for visual sentiment distribution prediction},
  journal   = {Signal Processing},
  volume    = {152},
  pages     = {206--216},
  year      = {2018},
  selected={true},
}

@article{DBLP:journals/spl/ZhangLJLS18,
  author    = {Jing Zhang and
               Xinhui Li and
               Peiguang Jing and
               Jing Liu and
               Yuting Su},
  title     = {Low-Rank Regularized Heterogeneous Tensor Decomposition for Subspace Clustering},
  journal   = {{IEEE} Signal Processing Letters},
  volume    = {25},
  number    = {3},
  pages     = {333--337},
  year      = {2018},
  selected={true},
}

@article{DBLP:journals/tkde/JingSNBLW18,
  author    = {Peiguang Jing and
               Yuting Su and
               Liqiang Nie and
               Xu Bai and
               Jing Liu and
               Meng Wang},
  title     = {Low-Rank Multi-View Embedding Learning for Micro-Video Popularity
               Prediction},
  journal   = {{IEEE} Transaction on Knowledge and Data Engineering},
  volume    = {30},
  number    = {8},
  pages     = {1519--1532},
  year      = {2018},
  selected={true},
}

@article{DBLP:journals/mta/SuWJX17,
  author    = {Yuting Su and
               Haiyi Wang and
               Peiguang Jing and
               Chuan{-}Zhong Xu},
  title     = {A spatial-temporal iterative tensor decomposition technique for action
               and gesture recognition},
  journal   = {Multimedia Tools and Applications},
  volume    = {76},
  number    = {8},
  pages     = {10635--10652},
  year      = {2017},
}

@article{DBLP:journals/tcyb/ZhangJSZS17,
  author    = {Luming Zhang and
               Peiguang Jing and
               Yuting Su and
               Chao Zhang and
               Ling Shao},
  title     = {SnapVideo: Personalized Video Generation for a Sightseeing Trip},
  journal   = {{IEEE} Transactions on  Cybernetics},
  volume    = {47},
  number    = {11},
  pages     = {3866--3878},
  year      = {2017},
}

@article{DBLP:journals/tmm/JingSNG17,
  author    = {Peiguang Jing and
               Yuting Su and
               Liqiang Nie and
               Huimin Gu},
  title     = {Predicting Image Memorability Through Adaptive Transfer Learning From
               External Sources},
  journal   = {{IEEE} Transactions on Multimedia},
  volume    = {19},
  number    = {5},
  pages     = {1050--1062},
  year      = {2017},
  selected={true},
}

@article{DBLP:journals/ijon/JingJYZ16,
  author    = {Peiguang Jing and
               Zhong Ji and
               Yunlong Yu and
               Zhongfei Zhang},
  title     = {Visual search reranking with RElevant Local Discriminant Analysis},
  journal   = {Neurocomputing},
  volume    = {173},
  pages     = {172--180},
  year      = {2016},
}

@article{DBLP:journals/jvcir/QiJWN16,
  author    = {Shuhan Qi and
               Peiguang Jing and
               Xuan Wang and
               Liqiang Nie},
  title     = {Quality biased multimedia data retrieval in microblogs},
  journal   = {Journal of Visual Communication and Image Representation},
  volume    = {40},
  pages     = {838--846},
  year      = {2016},
}

@article{DBLP:journals/spl/ZhangXJZS16,
  author    = {Jing Zhang and
               Chuan{-}Zhong Xu and
               Peiguang Jing and
               Chengqian Zhang and
               Yuting Su},
  title     = {A Tensor-Driven Temporal Correlation Model for Video Sequence Classification},
  journal   = {{IEEE} Signal Processing Letters},
  volume    = {23},
  number    = {9},
  pages     = {1246--1249},
  year      = {2016},
  selected={true},
}

@article{DBLP:journals/ijon/JiJYSL13,
  author    = {Zhong Ji and
               Peiguang Jing and
               Tianshi Yu and
               Yuting Su and
               Changshu Liu},
  title     = {Ranking Fisher discriminant analysis},
  journal   = {Neurocomputing},
  volume    = {120},
  pages     = {54--60},
  year      = {2013},
}

@article{DBLP:journals/sigpro/JiJSP13,
  author    = {Zhong Ji and
               Peiguang Jing and
               Yuting Su and
               Yanwei Pang},
  title     = {Rank canonical correlation analysis and its application in visual
               search reranking},
  journal   = {Signal Processing},
  volume    = {93},
  number    = {8},
  pages     = {2352--2360},
  year      = {2013},
}

@article{DBLP:journals/tnn/PangJJL13,
  author    = {Yanwei Pang and
               Zhong Ji and
               Peiguang Jing and
               Xuelong Li},
  title     = {Ranking Graph Embedding for Learning to Rerank},
  journal   = {{IEEE}  Transactions on Neural Networks and Learning Systems },
  volume    = {24},
  number    = {8},
  pages     = {1292--1303},
  year      = {2013},
  selected={true},
}


